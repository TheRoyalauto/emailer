{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 47, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/swizz/Desktop/Emailer/emailer/src/lib/scraper/crawler.ts"],"sourcesContent":["/**\r\n * Web Crawler - Fetches web pages with proper headers and timeout\r\n */\r\n\r\nconst USER_AGENTS = [\r\n    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\r\n    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\r\n    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',\r\n];\r\n\r\nexport interface CrawlResult {\r\n    url: string;\r\n    html: string;\r\n    success: boolean;\r\n    error?: string;\r\n}\r\n\r\n/**\r\n * Fetch a web page with timeout and proper headers\r\n */\r\nexport async function crawlPage(url: string, timeoutMs: number = 10000): Promise<CrawlResult> {\r\n    const controller = new AbortController();\r\n    const timeout = setTimeout(() => controller.abort(), timeoutMs);\r\n\r\n    try {\r\n        const userAgent = USER_AGENTS[Math.floor(Math.random() * USER_AGENTS.length)];\r\n\r\n        const response = await fetch(url, {\r\n            signal: controller.signal,\r\n            headers: {\r\n                'User-Agent': userAgent,\r\n                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\r\n                'Accept-Language': 'en-US,en;q=0.5',\r\n                'Accept-Encoding': 'gzip, deflate',\r\n                'Connection': 'keep-alive',\r\n            },\r\n        });\r\n\r\n        if (!response.ok) {\r\n            return { url, html: '', success: false, error: `HTTP ${response.status}` };\r\n        }\r\n\r\n        const html = await response.text();\r\n        return { url, html, success: true };\r\n    } catch (error) {\r\n        const message = error instanceof Error ? error.message : 'Unknown error';\r\n        return { url, html: '', success: false, error: message };\r\n    } finally {\r\n        clearTimeout(timeout);\r\n    }\r\n}\r\n\r\n/**\r\n * Crawl multiple pages with rate limiting\r\n */\r\nexport async function crawlPages(\r\n    urls: string[],\r\n    delayMs: number = 1000,\r\n    maxConcurrent: number = 5\r\n): Promise<CrawlResult[]> {\r\n    const results: CrawlResult[] = [];\r\n    const queue = [...urls];\r\n    const active: Promise<void>[] = [];\r\n\r\n    const processUrl = async (url: string) => {\r\n        const result = await crawlPage(url);\r\n        results.push(result);\r\n        await sleep(delayMs);\r\n    };\r\n\r\n    while (queue.length > 0 || active.length > 0) {\r\n        // Fill up to maxConcurrent\r\n        while (active.length < maxConcurrent && queue.length > 0) {\r\n            const url = queue.shift()!;\r\n            const promise = processUrl(url).then(() => {\r\n                const idx = active.indexOf(promise);\r\n                if (idx > -1) active.splice(idx, 1);\r\n            });\r\n            active.push(promise);\r\n        }\r\n\r\n        // Wait for at least one to complete\r\n        if (active.length > 0) {\r\n            await Promise.race(active);\r\n        }\r\n    }\r\n\r\n    return results;\r\n}\r\n\r\nfunction sleep(ms: number): Promise<void> {\r\n    return new Promise(resolve => setTimeout(resolve, ms));\r\n}\r\n"],"names":[],"mappings":"AAAA;;CAEC;;;;AAED,MAAM,cAAc;IAChB;IACA;IACA;CACH;AAYM,eAAe,UAAU,GAAW,EAAE,YAAoB,KAAK;IAClE,MAAM,aAAa,IAAI;IACvB,MAAM,UAAU,WAAW,IAAM,WAAW,KAAK,IAAI;IAErD,IAAI;QACA,MAAM,YAAY,WAAW,CAAC,KAAK,KAAK,CAAC,KAAK,MAAM,KAAK,YAAY,MAAM,EAAE;QAE7E,MAAM,WAAW,MAAM,MAAM,KAAK;YAC9B,QAAQ,WAAW,MAAM;YACzB,SAAS;gBACL,cAAc;gBACd,UAAU;gBACV,mBAAmB;gBACnB,mBAAmB;gBACnB,cAAc;YAClB;QACJ;QAEA,IAAI,CAAC,SAAS,EAAE,EAAE;YACd,OAAO;gBAAE;gBAAK,MAAM;gBAAI,SAAS;gBAAO,OAAO,CAAC,KAAK,EAAE,SAAS,MAAM,EAAE;YAAC;QAC7E;QAEA,MAAM,OAAO,MAAM,SAAS,IAAI;QAChC,OAAO;YAAE;YAAK;YAAM,SAAS;QAAK;IACtC,EAAE,OAAO,OAAO;QACZ,MAAM,UAAU,iBAAiB,QAAQ,MAAM,OAAO,GAAG;QACzD,OAAO;YAAE;YAAK,MAAM;YAAI,SAAS;YAAO,OAAO;QAAQ;IAC3D,SAAU;QACN,aAAa;IACjB;AACJ;AAKO,eAAe,WAClB,IAAc,EACd,UAAkB,IAAI,EACtB,gBAAwB,CAAC;IAEzB,MAAM,UAAyB,EAAE;IACjC,MAAM,QAAQ;WAAI;KAAK;IACvB,MAAM,SAA0B,EAAE;IAElC,MAAM,aAAa,OAAO;QACtB,MAAM,SAAS,MAAM,UAAU;QAC/B,QAAQ,IAAI,CAAC;QACb,MAAM,MAAM;IAChB;IAEA,MAAO,MAAM,MAAM,GAAG,KAAK,OAAO,MAAM,GAAG,EAAG;QAC1C,2BAA2B;QAC3B,MAAO,OAAO,MAAM,GAAG,iBAAiB,MAAM,MAAM,GAAG,EAAG;YACtD,MAAM,MAAM,MAAM,KAAK;YACvB,MAAM,UAAU,WAAW,KAAK,IAAI,CAAC;gBACjC,MAAM,MAAM,OAAO,OAAO,CAAC;gBAC3B,IAAI,MAAM,CAAC,GAAG,OAAO,MAAM,CAAC,KAAK;YACrC;YACA,OAAO,IAAI,CAAC;QAChB;QAEA,oCAAoC;QACpC,IAAI,OAAO,MAAM,GAAG,GAAG;YACnB,MAAM,QAAQ,IAAI,CAAC;QACvB;IACJ;IAEA,OAAO;AACX;AAEA,SAAS,MAAM,EAAU;IACrB,OAAO,IAAI,QAAQ,CAAA,UAAW,WAAW,SAAS;AACtD"}},
    {"offset": {"line": 130, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 336, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/swizz/Desktop/Emailer/emailer/src/lib/scraper/email-extractor.ts"],"sourcesContent":["/**\r\n * Email Extractor - Extracts email addresses from HTML content\r\n */\r\n\r\nimport * as cheerio from 'cheerio';\r\n\r\n// Email regex pattern - matches most valid emails\r\nconst EMAIL_REGEX = /[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}/g;\r\n\r\n// Common contact page paths to check\r\nconst CONTACT_PATHS = ['/contact', '/contact-us', '/about', '/about-us', '/team', '/staff'];\r\n\r\n// Blacklisted email patterns (not real contacts)\r\nconst EMAIL_BLACKLIST = [\r\n    'example.com',\r\n    'domain.com',\r\n    'email.com',\r\n    'yourcompany.com',\r\n    'sentry.io',\r\n    'wixpress.com',\r\n    'wordpress.com',\r\n    'squarespace.com',\r\n    '.png',\r\n    '.jpg',\r\n    '.gif',\r\n    '.svg',\r\n    'noreply',\r\n    'no-reply',\r\n    'donotreply',\r\n    'unsubscribe',\r\n];\r\n\r\nexport interface ExtractedContact {\r\n    email: string;\r\n    name?: string;\r\n    company?: string;\r\n    phone?: string;\r\n    location?: string;\r\n    website?: string;\r\n    address?: string;\r\n    source: string;\r\n}\r\n\r\n/**\r\n * Extract emails from HTML content\r\n */\r\nexport function extractEmailsFromHtml(html: string, sourceUrl: string): string[] {\r\n    const emails = new Set<string>();\r\n\r\n    // Method 1: Regex on raw HTML (catches obfuscated emails too)\r\n    const rawMatches = html.match(EMAIL_REGEX) || [];\r\n    rawMatches.forEach(email => emails.add(email.toLowerCase()));\r\n\r\n    // Method 2: Parse mailto: links\r\n    const $ = cheerio.load(html);\r\n    $('a[href^=\"mailto:\"]').each((_, el) => {\r\n        const href = $(el).attr('href') || '';\r\n        const email = href.replace('mailto:', '').split('?')[0].toLowerCase();\r\n        if (email.includes('@')) {\r\n            emails.add(email);\r\n        }\r\n    });\r\n\r\n    // Filter out blacklisted emails\r\n    const filtered = Array.from(emails).filter(email => {\r\n        return !EMAIL_BLACKLIST.some(blacklisted => email.includes(blacklisted));\r\n    });\r\n\r\n    return filtered;\r\n}\r\n\r\n/**\r\n * Extract phone numbers from HTML\r\n */\r\nexport function extractPhonesFromHtml(html: string): string[] {\r\n    const phones = new Set<string>();\r\n\r\n    // US phone patterns\r\n    const phonePatterns = [\r\n        /\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}/g,  // (555) 123-4567 or 555-123-4567\r\n        /\\d{3}[-.\\s]\\d{3}[-.\\s]\\d{4}/g,          // 555.123.4567\r\n        /\\+1[-.\\s]?\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}/g, // +1 555 123 4567\r\n    ];\r\n\r\n    phonePatterns.forEach(pattern => {\r\n        const matches = html.match(pattern) || [];\r\n        matches.forEach(phone => {\r\n            // Normalize phone format\r\n            const normalized = phone.replace(/\\D/g, '');\r\n            if (normalized.length >= 10 && normalized.length <= 11) {\r\n                phones.add(normalized.slice(-10)); // Last 10 digits\r\n            }\r\n        });\r\n    });\r\n\r\n    return Array.from(phones);\r\n}\r\n\r\n/**\r\n * Extract business name from HTML\r\n */\r\nexport function extractBusinessName(html: string, url: string): string | undefined {\r\n    const $ = cheerio.load(html);\r\n\r\n    // Try various meta tags and elements\r\n    const sources = [\r\n        $('meta[property=\"og:site_name\"]').attr('content'),\r\n        $('meta[name=\"application-name\"]').attr('content'),\r\n        $('meta[property=\"og:title\"]').attr('content'),\r\n        $('title').first().text(),\r\n        $('h1').first().text(),\r\n    ];\r\n\r\n    for (const source of sources) {\r\n        if (source && source.trim().length > 1 && source.length < 100) {\r\n            // Clean up the name\r\n            let name = source.trim()\r\n                .replace(/\\s*[-|–—]\\s*.*/g, '') // Remove anything after dash\r\n                .replace(/\\s*\\|\\s*.*/g, '')    // Remove anything after pipe\r\n                .trim();\r\n\r\n            if (name.length > 1) {\r\n                return name;\r\n            }\r\n        }\r\n    }\r\n\r\n    // Fallback: extract from domain\r\n    try {\r\n        const domain = new URL(url).hostname.replace('www.', '');\r\n        const name = domain.split('.')[0];\r\n        return name.charAt(0).toUpperCase() + name.slice(1);\r\n    } catch {\r\n        return undefined;\r\n    }\r\n}\r\n\r\n/**\r\n * Extract address from HTML\r\n */\r\nexport function extractAddress(html: string): string | undefined {\r\n    const $ = cheerio.load(html);\r\n\r\n    // Look for common address patterns\r\n    const addressPatterns = [\r\n        /\\d+\\s+[\\w\\s]+(?:Street|St|Avenue|Ave|Road|Rd|Boulevard|Blvd|Drive|Dr|Lane|Ln|Way|Court|Ct)[\\s,]+[\\w\\s]+,?\\s*[A-Z]{2}\\s+\\d{5}/gi,\r\n    ];\r\n\r\n    for (const pattern of addressPatterns) {\r\n        const match = html.match(pattern);\r\n        if (match && match[0]) {\r\n            return match[0].trim();\r\n        }\r\n    }\r\n\r\n    // Try schema.org markup\r\n    const streetAddress = $('[itemprop=\"streetAddress\"]').first().text();\r\n    const locality = $('[itemprop=\"addressLocality\"]').first().text();\r\n    const region = $('[itemprop=\"addressRegion\"]').first().text();\r\n    const postalCode = $('[itemprop=\"postalCode\"]').first().text();\r\n\r\n    if (streetAddress && locality) {\r\n        return `${streetAddress}, ${locality}${region ? ', ' + region : ''}${postalCode ? ' ' + postalCode : ''}`.trim();\r\n    }\r\n\r\n    return undefined;\r\n}\r\n\r\n/**\r\n * Get contact page URLs for a given website\r\n */\r\nexport function getContactPageUrls(baseUrl: string): string[] {\r\n    try {\r\n        const url = new URL(baseUrl);\r\n        const origin = url.origin;\r\n        return CONTACT_PATHS.map(path => origin + path);\r\n    } catch {\r\n        return [];\r\n    }\r\n}\r\n\r\n/**\r\n * Extract all contact info from HTML\r\n */\r\nexport function extractContactInfo(html: string, sourceUrl: string): Partial<ExtractedContact> {\r\n    const emails = extractEmailsFromHtml(html, sourceUrl);\r\n    const phones = extractPhonesFromHtml(html);\r\n    const company = extractBusinessName(html, sourceUrl);\r\n    const address = extractAddress(html);\r\n\r\n    return {\r\n        email: emails[0],\r\n        company,\r\n        phone: phones[0] ? formatPhone(phones[0]) : undefined,\r\n        address,\r\n        website: new URL(sourceUrl).origin,\r\n        source: sourceUrl,\r\n    };\r\n}\r\n\r\nfunction formatPhone(digits: string): string {\r\n    if (digits.length === 10) {\r\n        return `(${digits.slice(0, 3)}) ${digits.slice(3, 6)}-${digits.slice(6)}`;\r\n    }\r\n    return digits;\r\n}\r\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;;;AAED;AAAA;;AAEA,kDAAkD;AAClD,MAAM,cAAc;AAEpB,qCAAqC;AACrC,MAAM,gBAAgB;IAAC;IAAY;IAAe;IAAU;IAAa;IAAS;CAAS;AAE3F,iDAAiD;AACjD,MAAM,kBAAkB;IACpB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;CACH;AAgBM,SAAS,sBAAsB,IAAY,EAAE,SAAiB;IACjE,MAAM,SAAS,IAAI;IAEnB,8DAA8D;IAC9D,MAAM,aAAa,KAAK,KAAK,CAAC,gBAAgB,EAAE;IAChD,WAAW,OAAO,CAAC,CAAA,QAAS,OAAO,GAAG,CAAC,MAAM,WAAW;IAExD,gCAAgC;IAChC,MAAM,IAAI,kJAAQ,IAAI,CAAC;IACvB,EAAE,sBAAsB,IAAI,CAAC,CAAC,GAAG;QAC7B,MAAM,OAAO,EAAE,IAAI,IAAI,CAAC,WAAW;QACnC,MAAM,QAAQ,KAAK,OAAO,CAAC,WAAW,IAAI,KAAK,CAAC,IAAI,CAAC,EAAE,CAAC,WAAW;QACnE,IAAI,MAAM,QAAQ,CAAC,MAAM;YACrB,OAAO,GAAG,CAAC;QACf;IACJ;IAEA,gCAAgC;IAChC,MAAM,WAAW,MAAM,IAAI,CAAC,QAAQ,MAAM,CAAC,CAAA;QACvC,OAAO,CAAC,gBAAgB,IAAI,CAAC,CAAA,cAAe,MAAM,QAAQ,CAAC;IAC/D;IAEA,OAAO;AACX;AAKO,SAAS,sBAAsB,IAAY;IAC9C,MAAM,SAAS,IAAI;IAEnB,oBAAoB;IACpB,MAAM,gBAAgB;QAClB;QACA;QACA;KACH;IAED,cAAc,OAAO,CAAC,CAAA;QAClB,MAAM,UAAU,KAAK,KAAK,CAAC,YAAY,EAAE;QACzC,QAAQ,OAAO,CAAC,CAAA;YACZ,yBAAyB;YACzB,MAAM,aAAa,MAAM,OAAO,CAAC,OAAO;YACxC,IAAI,WAAW,MAAM,IAAI,MAAM,WAAW,MAAM,IAAI,IAAI;gBACpD,OAAO,GAAG,CAAC,WAAW,KAAK,CAAC,CAAC,MAAM,iBAAiB;YACxD;QACJ;IACJ;IAEA,OAAO,MAAM,IAAI,CAAC;AACtB;AAKO,SAAS,oBAAoB,IAAY,EAAE,GAAW;IACzD,MAAM,IAAI,kJAAQ,IAAI,CAAC;IAEvB,qCAAqC;IACrC,MAAM,UAAU;QACZ,EAAE,iCAAiC,IAAI,CAAC;QACxC,EAAE,iCAAiC,IAAI,CAAC;QACxC,EAAE,6BAA6B,IAAI,CAAC;QACpC,EAAE,SAAS,KAAK,GAAG,IAAI;QACvB,EAAE,MAAM,KAAK,GAAG,IAAI;KACvB;IAED,KAAK,MAAM,UAAU,QAAS;QAC1B,IAAI,UAAU,OAAO,IAAI,GAAG,MAAM,GAAG,KAAK,OAAO,MAAM,GAAG,KAAK;YAC3D,oBAAoB;YACpB,IAAI,OAAO,OAAO,IAAI,GACjB,OAAO,CAAC,mBAAmB,IAAI,6BAA6B;aAC5D,OAAO,CAAC,eAAe,IAAO,6BAA6B;aAC3D,IAAI;YAET,IAAI,KAAK,MAAM,GAAG,GAAG;gBACjB,OAAO;YACX;QACJ;IACJ;IAEA,gCAAgC;IAChC,IAAI;QACA,MAAM,SAAS,IAAI,IAAI,KAAK,QAAQ,CAAC,OAAO,CAAC,QAAQ;QACrD,MAAM,OAAO,OAAO,KAAK,CAAC,IAAI,CAAC,EAAE;QACjC,OAAO,KAAK,MAAM,CAAC,GAAG,WAAW,KAAK,KAAK,KAAK,CAAC;IACrD,EAAE,OAAM;QACJ,OAAO;IACX;AACJ;AAKO,SAAS,eAAe,IAAY;IACvC,MAAM,IAAI,kJAAQ,IAAI,CAAC;IAEvB,mCAAmC;IACnC,MAAM,kBAAkB;QACpB;KACH;IAED,KAAK,MAAM,WAAW,gBAAiB;QACnC,MAAM,QAAQ,KAAK,KAAK,CAAC;QACzB,IAAI,SAAS,KAAK,CAAC,EAAE,EAAE;YACnB,OAAO,KAAK,CAAC,EAAE,CAAC,IAAI;QACxB;IACJ;IAEA,wBAAwB;IACxB,MAAM,gBAAgB,EAAE,8BAA8B,KAAK,GAAG,IAAI;IAClE,MAAM,WAAW,EAAE,gCAAgC,KAAK,GAAG,IAAI;IAC/D,MAAM,SAAS,EAAE,8BAA8B,KAAK,GAAG,IAAI;IAC3D,MAAM,aAAa,EAAE,2BAA2B,KAAK,GAAG,IAAI;IAE5D,IAAI,iBAAiB,UAAU;QAC3B,OAAO,GAAG,cAAc,EAAE,EAAE,WAAW,SAAS,OAAO,SAAS,KAAK,aAAa,MAAM,aAAa,IAAI,CAAC,IAAI;IAClH;IAEA,OAAO;AACX;AAKO,SAAS,mBAAmB,OAAe;IAC9C,IAAI;QACA,MAAM,MAAM,IAAI,IAAI;QACpB,MAAM,SAAS,IAAI,MAAM;QACzB,OAAO,cAAc,GAAG,CAAC,CAAA,OAAQ,SAAS;IAC9C,EAAE,OAAM;QACJ,OAAO,EAAE;IACb;AACJ;AAKO,SAAS,mBAAmB,IAAY,EAAE,SAAiB;IAC9D,MAAM,SAAS,sBAAsB,MAAM;IAC3C,MAAM,SAAS,sBAAsB;IACrC,MAAM,UAAU,oBAAoB,MAAM;IAC1C,MAAM,UAAU,eAAe;IAE/B,OAAO;QACH,OAAO,MAAM,CAAC,EAAE;QAChB;QACA,OAAO,MAAM,CAAC,EAAE,GAAG,YAAY,MAAM,CAAC,EAAE,IAAI;QAC5C;QACA,SAAS,IAAI,IAAI,WAAW,MAAM;QAClC,QAAQ;IACZ;AACJ;AAEA,SAAS,YAAY,MAAc;IAC/B,IAAI,OAAO,MAAM,KAAK,IAAI;QACtB,OAAO,CAAC,CAAC,EAAE,OAAO,KAAK,CAAC,GAAG,GAAG,EAAE,EAAE,OAAO,KAAK,CAAC,GAAG,GAAG,CAAC,EAAE,OAAO,KAAK,CAAC,IAAI;IAC7E;IACA,OAAO;AACX"}},
    {"offset": {"line": 500, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 514, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/swizz/Desktop/Emailer/emailer/src/lib/scraper/email-validator.ts"],"sourcesContent":["/**\r\n * Email Validator - Validates email addresses via syntax and MX records\r\n */\r\n\r\nimport { promises as dns } from 'dns';\r\n\r\n/**\r\n * Validate email syntax\r\n */\r\nexport function isValidEmailSyntax(email: string): boolean {\r\n    const emailRegex = /^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$/;\r\n    return emailRegex.test(email);\r\n}\r\n\r\n/**\r\n * Check if domain has MX records (can receive email)\r\n */\r\nexport async function hasMxRecords(domain: string): Promise<boolean> {\r\n    try {\r\n        const records = await dns.resolveMx(domain);\r\n        return records && records.length > 0;\r\n    } catch {\r\n        return false;\r\n    }\r\n}\r\n\r\n/**\r\n * Check if email domain is a disposable/temp email service\r\n */\r\nconst DISPOSABLE_DOMAINS = new Set([\r\n    'tempmail.com', 'throwaway.email', 'guerrillamail.com', 'mailinator.com',\r\n    '10minutemail.com', 'temp-mail.org', 'fakeinbox.com', 'tempail.com',\r\n    'getnada.com', 'maildrop.cc', 'yopmail.com', 'trashmail.com',\r\n]);\r\n\r\nexport function isDisposableEmail(email: string): boolean {\r\n    const domain = email.split('@')[1]?.toLowerCase();\r\n    return DISPOSABLE_DOMAINS.has(domain);\r\n}\r\n\r\n/**\r\n * Full email validation\r\n */\r\nexport interface ValidationResult {\r\n    email: string;\r\n    valid: boolean;\r\n    reason?: string;\r\n}\r\n\r\nexport async function validateEmail(email: string): Promise<ValidationResult> {\r\n    const normalized = email.toLowerCase().trim();\r\n\r\n    // Syntax check\r\n    if (!isValidEmailSyntax(normalized)) {\r\n        return { email: normalized, valid: false, reason: 'Invalid syntax' };\r\n    }\r\n\r\n    // Disposable check\r\n    if (isDisposableEmail(normalized)) {\r\n        return { email: normalized, valid: false, reason: 'Disposable email' };\r\n    }\r\n\r\n    // MX record check\r\n    const domain = normalized.split('@')[1];\r\n    const hasMx = await hasMxRecords(domain);\r\n    if (!hasMx) {\r\n        return { email: normalized, valid: false, reason: 'No MX records' };\r\n    }\r\n\r\n    return { email: normalized, valid: true };\r\n}\r\n\r\n/**\r\n * Validate multiple emails concurrently\r\n */\r\nexport async function validateEmails(emails: string[]): Promise<ValidationResult[]> {\r\n    return Promise.all(emails.map(validateEmail));\r\n}\r\n\r\n/**\r\n * Calculate lead score based on available information\r\n */\r\nexport function calculateLeadScore(contact: {\r\n    email?: string;\r\n    phone?: string;\r\n    company?: string;\r\n    website?: string;\r\n    address?: string;\r\n}): number {\r\n    let score = 0;\r\n\r\n    // Email quality\r\n    if (contact.email) {\r\n        score += 30;\r\n        // Business email domains score higher\r\n        const domain = contact.email.split('@')[1];\r\n        if (!['gmail.com', 'yahoo.com', 'hotmail.com', 'outlook.com', 'aol.com'].includes(domain)) {\r\n            score += 15; // Business domain bonus\r\n        }\r\n    }\r\n\r\n    // Phone number\r\n    if (contact.phone) {\r\n        score += 20;\r\n    }\r\n\r\n    // Company name\r\n    if (contact.company && contact.company.length > 2) {\r\n        score += 15;\r\n    }\r\n\r\n    // Website\r\n    if (contact.website) {\r\n        score += 10;\r\n    }\r\n\r\n    // Physical address\r\n    if (contact.address) {\r\n        score += 10;\r\n    }\r\n\r\n    return Math.min(score, 100);\r\n}\r\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;;;AAED;;AAKO,SAAS,mBAAmB,KAAa;IAC5C,MAAM,aAAa;IACnB,OAAO,WAAW,IAAI,CAAC;AAC3B;AAKO,eAAe,aAAa,MAAc;IAC7C,IAAI;QACA,MAAM,UAAU,MAAM,4FAAA,CAAA,WAAG,CAAC,SAAS,CAAC;QACpC,OAAO,WAAW,QAAQ,MAAM,GAAG;IACvC,EAAE,OAAM;QACJ,OAAO;IACX;AACJ;AAEA;;CAEC,GACD,MAAM,qBAAqB,IAAI,IAAI;IAC/B;IAAgB;IAAmB;IAAqB;IACxD;IAAoB;IAAiB;IAAiB;IACtD;IAAe;IAAe;IAAe;CAChD;AAEM,SAAS,kBAAkB,KAAa;IAC3C,MAAM,SAAS,MAAM,KAAK,CAAC,IAAI,CAAC,EAAE,EAAE;IACpC,OAAO,mBAAmB,GAAG,CAAC;AAClC;AAWO,eAAe,cAAc,KAAa;IAC7C,MAAM,aAAa,MAAM,WAAW,GAAG,IAAI;IAE3C,eAAe;IACf,IAAI,CAAC,mBAAmB,aAAa;QACjC,OAAO;YAAE,OAAO;YAAY,OAAO;YAAO,QAAQ;QAAiB;IACvE;IAEA,mBAAmB;IACnB,IAAI,kBAAkB,aAAa;QAC/B,OAAO;YAAE,OAAO;YAAY,OAAO;YAAO,QAAQ;QAAmB;IACzE;IAEA,kBAAkB;IAClB,MAAM,SAAS,WAAW,KAAK,CAAC,IAAI,CAAC,EAAE;IACvC,MAAM,QAAQ,MAAM,aAAa;IACjC,IAAI,CAAC,OAAO;QACR,OAAO;YAAE,OAAO;YAAY,OAAO;YAAO,QAAQ;QAAgB;IACtE;IAEA,OAAO;QAAE,OAAO;QAAY,OAAO;IAAK;AAC5C;AAKO,eAAe,eAAe,MAAgB;IACjD,OAAO,QAAQ,GAAG,CAAC,OAAO,GAAG,CAAC;AAClC;AAKO,SAAS,mBAAmB,OAMlC;IACG,IAAI,QAAQ;IAEZ,gBAAgB;IAChB,IAAI,QAAQ,KAAK,EAAE;QACf,SAAS;QACT,sCAAsC;QACtC,MAAM,SAAS,QAAQ,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE;QAC1C,IAAI,CAAC;YAAC;YAAa;YAAa;YAAe;YAAe;SAAU,CAAC,QAAQ,CAAC,SAAS;YACvF,SAAS,IAAI,wBAAwB;QACzC;IACJ;IAEA,eAAe;IACf,IAAI,QAAQ,KAAK,EAAE;QACf,SAAS;IACb;IAEA,eAAe;IACf,IAAI,QAAQ,OAAO,IAAI,QAAQ,OAAO,CAAC,MAAM,GAAG,GAAG;QAC/C,SAAS;IACb;IAEA,UAAU;IACV,IAAI,QAAQ,OAAO,EAAE;QACjB,SAAS;IACb;IAEA,mBAAmB;IACnB,IAAI,QAAQ,OAAO,EAAE;QACjB,SAAS;IACb;IAEA,OAAO,KAAK,GAAG,CAAC,OAAO;AAC3B"}},
    {"offset": {"line": 629, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 635, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/swizz/Desktop/Emailer/emailer/src/lib/scraper/index.ts"],"sourcesContent":["/**\r\n * Real Lead Scraper - Direct Website Scraping\r\n * Searches Google, extracts actual business websites, and scrapes contact info\r\n */\r\n\r\nimport { crawlPage, CrawlResult } from './crawler';\r\nimport { extractContactInfo, extractEmailsFromHtml, extractPhonesFromHtml, extractBusinessName, ExtractedContact, getContactPageUrls } from './email-extractor';\r\nimport { validateEmail, calculateLeadScore, ValidationResult } from './email-validator';\r\n\r\nexport interface ScrapedLead {\r\n    email: string;\r\n    name?: string;\r\n    company?: string;\r\n    phone?: string;\r\n    location?: string;\r\n    website?: string;\r\n    address?: string;\r\n    leadScore: number;\r\n    verified: boolean;\r\n    source: string;\r\n}\r\n\r\nexport interface ScrapeResult {\r\n    leads: ScrapedLead[];\r\n    totalScraped: number;\r\n    errors: string[];\r\n}\r\n\r\n/**\r\n * Main scraping function - searches and extracts real contact info\r\n */\r\nexport async function scrapeLeads(\r\n    prompt: string,\r\n    maxResults: number = 20\r\n): Promise<ScrapeResult> {\r\n    const errors: string[] = [];\r\n    const leads: ScrapedLead[] = [];\r\n    const seenEmails = new Set<string>();\r\n\r\n    console.log(`[Scraper] Searching for: ${prompt}`);\r\n\r\n    // Parse the search query\r\n    const { businessType, location } = parseQuery(prompt);\r\n\r\n    if (!businessType) {\r\n        errors.push('Could not determine business type from query');\r\n        return { leads: [], totalScraped: 0, errors };\r\n    }\r\n\r\n    // Try Google Custom Search API first\r\n    const searchResults = await googleCustomSearch(businessType, location, maxResults);\r\n\r\n    if (searchResults.length === 0) {\r\n        errors.push('No search results found. Try a different search term or location.');\r\n        return { leads: [], totalScraped: 0, errors };\r\n    }\r\n\r\n    console.log(`[Scraper] Found ${searchResults.length} search results`);\r\n\r\n    // Crawl each result and extract contact info\r\n    let scraped = 0;\r\n    for (const result of searchResults) {\r\n        if (leads.length >= maxResults) break;\r\n\r\n        try {\r\n            // Skip non-business URLs\r\n            if (isDirectoryUrl(result.url)) {\r\n                console.log(`[Scraper] Skipping directory: ${result.url}`);\r\n                continue;\r\n            }\r\n\r\n            console.log(`[Scraper] Crawling: ${result.url}`);\r\n            const crawlResult: CrawlResult = await crawlPage(result.url);\r\n            scraped++;\r\n\r\n            if (!crawlResult.success || !crawlResult.html) {\r\n                console.log(`[Scraper] No HTML from: ${result.url} - ${crawlResult.error}`);\r\n                continue;\r\n            }\r\n\r\n            const html = crawlResult.html;\r\n\r\n            // Extract emails and contact info\r\n            let emails = extractEmailsFromHtml(html, result.url);\r\n            const phones = extractPhonesFromHtml(html);\r\n            const company = extractBusinessName(html, result.url);\r\n            const contactInfo = extractContactInfo(html, result.url);\r\n\r\n            // If no emails found on main page, try contact page\r\n            if (emails.length === 0) {\r\n                const contactUrls = getContactPageUrls(result.url);\r\n                for (const contactUrl of contactUrls.slice(0, 2)) { // Check first 2 contact pages\r\n                    try {\r\n                        const contactCrawl = await crawlPage(contactUrl);\r\n                        if (contactCrawl.success && contactCrawl.html) {\r\n                            const moreEmails = extractEmailsFromHtml(contactCrawl.html, contactUrl);\r\n                            emails.push(...moreEmails);\r\n                            scraped++;\r\n                        }\r\n                    } catch {\r\n                        // Ignore contact page errors\r\n                    }\r\n                }\r\n            }\r\n\r\n            // Process found emails\r\n            for (const email of emails) {\r\n                if (seenEmails.has(email.toLowerCase())) continue;\r\n                if (leads.length >= maxResults) break;\r\n\r\n                // Validate email\r\n                const validation: ValidationResult = await validateEmail(email);\r\n\r\n                if (!validation.valid) {\r\n                    console.log(`[Scraper] Invalid email: ${email} - ${validation.reason}`);\r\n                    continue;\r\n                }\r\n\r\n                seenEmails.add(email.toLowerCase());\r\n\r\n                // Calculate lead score\r\n                const leadScore = calculateLeadScore({\r\n                    email,\r\n                    phone: phones[0],\r\n                    company,\r\n                    website: result.url,\r\n                    address: contactInfo.address,\r\n                });\r\n\r\n                leads.push({\r\n                    email,\r\n                    name: undefined, // We don't generate fake names\r\n                    company: company || extractCompanyFromUrl(result.url),\r\n                    phone: phones[0] ? formatPhone(phones[0]) : undefined,\r\n                    location: location || undefined,\r\n                    website: result.url,\r\n                    address: contactInfo.address,\r\n                    leadScore,\r\n                    verified: validation.valid,\r\n                    source: result.url,\r\n                });\r\n\r\n                console.log(`[Scraper] Found lead: ${email} from ${result.url}`);\r\n            }\r\n        } catch (error) {\r\n            const msg = error instanceof Error ? error.message : 'Unknown error';\r\n            console.log(`[Scraper] Error crawling ${result.url}: ${msg}`);\r\n            errors.push(`Failed to crawl ${result.url}: ${msg}`);\r\n        }\r\n    }\r\n\r\n    console.log(`[Scraper] Completed: ${leads.length} leads from ${scraped} pages`);\r\n\r\n    return {\r\n        leads,\r\n        totalScraped: scraped,\r\n        errors,\r\n    };\r\n}\r\n\r\n/**\r\n * Parse user query into business type and location\r\n */\r\nfunction parseQuery(prompt: string): { businessType: string; location: string } {\r\n    const lower = prompt.toLowerCase();\r\n\r\n    // Extract location\r\n    const locationMatch = lower.match(/in\\s+([^,]+(?:,\\s*[a-z]{2,})?)/i);\r\n    const location = locationMatch ? locationMatch[1].trim() : '';\r\n\r\n    // Extract business type (everything before \"in location\")\r\n    let businessType = lower\r\n        .replace(/find\\s+(me\\s+)?/i, '')\r\n        .replace(/search\\s+(for\\s+)?/i, '')\r\n        .replace(/get\\s+(me\\s+)?/i, '')\r\n        .replace(/\\d+\\s*/g, '')\r\n        .replace(/in\\s+.*/i, '')\r\n        .trim();\r\n\r\n    return { businessType, location };\r\n}\r\n\r\n/**\r\n * Google Custom Search API\r\n */\r\nasync function googleCustomSearch(\r\n    businessType: string,\r\n    location: string,\r\n    numResults: number\r\n): Promise<{ title: string; url: string }[]> {\r\n    const apiKey = process.env.GOOGLE_SEARCH_API_KEY;\r\n    const engineId = process.env.GOOGLE_SEARCH_ENGINE_ID;\r\n\r\n    if (!apiKey || !engineId) {\r\n        console.log('[Scraper] Google Search API not configured');\r\n        return [];\r\n    }\r\n\r\n    const query = `${businessType} ${location} contact email`.trim();\r\n\r\n    try {\r\n        const url = new URL('https://www.googleapis.com/customsearch/v1');\r\n        url.searchParams.set('key', apiKey);\r\n        url.searchParams.set('cx', engineId);\r\n        url.searchParams.set('q', query);\r\n        url.searchParams.set('num', String(Math.min(numResults, 10)));\r\n\r\n        const response = await fetch(url.toString());\r\n\r\n        if (!response.ok) {\r\n            const errorText = await response.text();\r\n            console.error(`[Scraper] Google Search API error: ${response.status}`, errorText);\r\n            return [];\r\n        }\r\n\r\n        const data = await response.json();\r\n\r\n        if (!data.items || data.items.length === 0) {\r\n            console.log('[Scraper] No search results from Google');\r\n            return [];\r\n        }\r\n\r\n        return data.items.map((item: any) => ({\r\n            title: item.title || '',\r\n            url: item.link || '',\r\n        }));\r\n    } catch (error) {\r\n        console.error('[Scraper] Google Search error:', error);\r\n        return [];\r\n    }\r\n}\r\n\r\n/**\r\n * Check if URL is a directory (not a business website)\r\n */\r\nfunction isDirectoryUrl(url: string): boolean {\r\n    const directories = [\r\n        'yelp.com',\r\n        'yellowpages.com',\r\n        'google.com/maps',\r\n        'facebook.com',\r\n        'linkedin.com',\r\n        'bing.com',\r\n        'mapquest.com',\r\n        'manta.com',\r\n        'bbb.org',\r\n        'angi.com',\r\n        'thumbtack.com',\r\n        'nextdoor.com',\r\n    ];\r\n\r\n    return directories.some(dir => url.includes(dir));\r\n}\r\n\r\n/**\r\n * Extract company name from URL\r\n */\r\nfunction extractCompanyFromUrl(url: string): string | undefined {\r\n    try {\r\n        const hostname = new URL(url).hostname;\r\n        // Remove www. and common TLDs\r\n        return hostname\r\n            .replace(/^www\\./, '')\r\n            .replace(/\\.(com|net|org|biz|info|co)$/i, '')\r\n            .split('.')[0]\r\n            .replace(/-/g, ' ')\r\n            .replace(/\\b\\w/g, c => c.toUpperCase());\r\n    } catch {\r\n        return undefined;\r\n    }\r\n}\r\n\r\n/**\r\n * Format phone number\r\n */\r\nfunction formatPhone(digits: string): string {\r\n    const clean = digits.replace(/\\D/g, '');\r\n    if (clean.length === 10) {\r\n        return `(${clean.slice(0, 3)}) ${clean.slice(3, 6)}-${clean.slice(6)}`;\r\n    }\r\n    return digits;\r\n}\r\n"],"names":[],"mappings":"AAAA;;;CAGC;;;AAED;AACA;AACA;;;;AAwBO,eAAe,YAClB,MAAc,EACd,aAAqB,EAAE;IAEvB,MAAM,SAAmB,EAAE;IAC3B,MAAM,QAAuB,EAAE;IAC/B,MAAM,aAAa,IAAI;IAEvB,QAAQ,GAAG,CAAC,CAAC,yBAAyB,EAAE,QAAQ;IAEhD,yBAAyB;IACzB,MAAM,EAAE,YAAY,EAAE,QAAQ,EAAE,GAAG,WAAW;IAE9C,IAAI,CAAC,cAAc;QACf,OAAO,IAAI,CAAC;QACZ,OAAO;YAAE,OAAO,EAAE;YAAE,cAAc;YAAG;QAAO;IAChD;IAEA,qCAAqC;IACrC,MAAM,gBAAgB,MAAM,mBAAmB,cAAc,UAAU;IAEvE,IAAI,cAAc,MAAM,KAAK,GAAG;QAC5B,OAAO,IAAI,CAAC;QACZ,OAAO;YAAE,OAAO,EAAE;YAAE,cAAc;YAAG;QAAO;IAChD;IAEA,QAAQ,GAAG,CAAC,CAAC,gBAAgB,EAAE,cAAc,MAAM,CAAC,eAAe,CAAC;IAEpE,6CAA6C;IAC7C,IAAI,UAAU;IACd,KAAK,MAAM,UAAU,cAAe;QAChC,IAAI,MAAM,MAAM,IAAI,YAAY;QAEhC,IAAI;YACA,yBAAyB;YACzB,IAAI,eAAe,OAAO,GAAG,GAAG;gBAC5B,QAAQ,GAAG,CAAC,CAAC,8BAA8B,EAAE,OAAO,GAAG,EAAE;gBACzD;YACJ;YAEA,QAAQ,GAAG,CAAC,CAAC,oBAAoB,EAAE,OAAO,GAAG,EAAE;YAC/C,MAAM,cAA2B,MAAM,CAAA,GAAA,kIAAA,CAAA,YAAS,AAAD,EAAE,OAAO,GAAG;YAC3D;YAEA,IAAI,CAAC,YAAY,OAAO,IAAI,CAAC,YAAY,IAAI,EAAE;gBAC3C,QAAQ,GAAG,CAAC,CAAC,wBAAwB,EAAE,OAAO,GAAG,CAAC,GAAG,EAAE,YAAY,KAAK,EAAE;gBAC1E;YACJ;YAEA,MAAM,OAAO,YAAY,IAAI;YAE7B,kCAAkC;YAClC,IAAI,SAAS,CAAA,GAAA,6IAAA,CAAA,wBAAqB,AAAD,EAAE,MAAM,OAAO,GAAG;YACnD,MAAM,SAAS,CAAA,GAAA,6IAAA,CAAA,wBAAqB,AAAD,EAAE;YACrC,MAAM,UAAU,CAAA,GAAA,6IAAA,CAAA,sBAAmB,AAAD,EAAE,MAAM,OAAO,GAAG;YACpD,MAAM,cAAc,CAAA,GAAA,6IAAA,CAAA,qBAAkB,AAAD,EAAE,MAAM,OAAO,GAAG;YAEvD,oDAAoD;YACpD,IAAI,OAAO,MAAM,KAAK,GAAG;gBACrB,MAAM,cAAc,CAAA,GAAA,6IAAA,CAAA,qBAAkB,AAAD,EAAE,OAAO,GAAG;gBACjD,KAAK,MAAM,cAAc,YAAY,KAAK,CAAC,GAAG,GAAI;oBAC9C,IAAI;wBACA,MAAM,eAAe,MAAM,CAAA,GAAA,kIAAA,CAAA,YAAS,AAAD,EAAE;wBACrC,IAAI,aAAa,OAAO,IAAI,aAAa,IAAI,EAAE;4BAC3C,MAAM,aAAa,CAAA,GAAA,6IAAA,CAAA,wBAAqB,AAAD,EAAE,aAAa,IAAI,EAAE;4BAC5D,OAAO,IAAI,IAAI;4BACf;wBACJ;oBACJ,EAAE,OAAM;oBACJ,6BAA6B;oBACjC;gBACJ;YACJ;YAEA,uBAAuB;YACvB,KAAK,MAAM,SAAS,OAAQ;gBACxB,IAAI,WAAW,GAAG,CAAC,MAAM,WAAW,KAAK;gBACzC,IAAI,MAAM,MAAM,IAAI,YAAY;gBAEhC,iBAAiB;gBACjB,MAAM,aAA+B,MAAM,CAAA,GAAA,6IAAA,CAAA,gBAAa,AAAD,EAAE;gBAEzD,IAAI,CAAC,WAAW,KAAK,EAAE;oBACnB,QAAQ,GAAG,CAAC,CAAC,yBAAyB,EAAE,MAAM,GAAG,EAAE,WAAW,MAAM,EAAE;oBACtE;gBACJ;gBAEA,WAAW,GAAG,CAAC,MAAM,WAAW;gBAEhC,uBAAuB;gBACvB,MAAM,YAAY,CAAA,GAAA,6IAAA,CAAA,qBAAkB,AAAD,EAAE;oBACjC;oBACA,OAAO,MAAM,CAAC,EAAE;oBAChB;oBACA,SAAS,OAAO,GAAG;oBACnB,SAAS,YAAY,OAAO;gBAChC;gBAEA,MAAM,IAAI,CAAC;oBACP;oBACA,MAAM;oBACN,SAAS,WAAW,sBAAsB,OAAO,GAAG;oBACpD,OAAO,MAAM,CAAC,EAAE,GAAG,YAAY,MAAM,CAAC,EAAE,IAAI;oBAC5C,UAAU,YAAY;oBACtB,SAAS,OAAO,GAAG;oBACnB,SAAS,YAAY,OAAO;oBAC5B;oBACA,UAAU,WAAW,KAAK;oBAC1B,QAAQ,OAAO,GAAG;gBACtB;gBAEA,QAAQ,GAAG,CAAC,CAAC,sBAAsB,EAAE,MAAM,MAAM,EAAE,OAAO,GAAG,EAAE;YACnE;QACJ,EAAE,OAAO,OAAO;YACZ,MAAM,MAAM,iBAAiB,QAAQ,MAAM,OAAO,GAAG;YACrD,QAAQ,GAAG,CAAC,CAAC,yBAAyB,EAAE,OAAO,GAAG,CAAC,EAAE,EAAE,KAAK;YAC5D,OAAO,IAAI,CAAC,CAAC,gBAAgB,EAAE,OAAO,GAAG,CAAC,EAAE,EAAE,KAAK;QACvD;IACJ;IAEA,QAAQ,GAAG,CAAC,CAAC,qBAAqB,EAAE,MAAM,MAAM,CAAC,YAAY,EAAE,QAAQ,MAAM,CAAC;IAE9E,OAAO;QACH;QACA,cAAc;QACd;IACJ;AACJ;AAEA;;CAEC,GACD,SAAS,WAAW,MAAc;IAC9B,MAAM,QAAQ,OAAO,WAAW;IAEhC,mBAAmB;IACnB,MAAM,gBAAgB,MAAM,KAAK,CAAC;IAClC,MAAM,WAAW,gBAAgB,aAAa,CAAC,EAAE,CAAC,IAAI,KAAK;IAE3D,0DAA0D;IAC1D,IAAI,eAAe,MACd,OAAO,CAAC,oBAAoB,IAC5B,OAAO,CAAC,uBAAuB,IAC/B,OAAO,CAAC,mBAAmB,IAC3B,OAAO,CAAC,WAAW,IACnB,OAAO,CAAC,YAAY,IACpB,IAAI;IAET,OAAO;QAAE;QAAc;IAAS;AACpC;AAEA;;CAEC,GACD,eAAe,mBACX,YAAoB,EACpB,QAAgB,EAChB,UAAkB;IAElB,MAAM,SAAS,QAAQ,GAAG,CAAC,qBAAqB;IAChD,MAAM,WAAW,QAAQ,GAAG,CAAC,uBAAuB;IAEpD,IAAI,CAAC,UAAU,CAAC,UAAU;QACtB,QAAQ,GAAG,CAAC;QACZ,OAAO,EAAE;IACb;IAEA,MAAM,QAAQ,GAAG,aAAa,CAAC,EAAE,SAAS,cAAc,CAAC,CAAC,IAAI;IAE9D,IAAI;QACA,MAAM,MAAM,IAAI,IAAI;QACpB,IAAI,YAAY,CAAC,GAAG,CAAC,OAAO;QAC5B,IAAI,YAAY,CAAC,GAAG,CAAC,MAAM;QAC3B,IAAI,YAAY,CAAC,GAAG,CAAC,KAAK;QAC1B,IAAI,YAAY,CAAC,GAAG,CAAC,OAAO,OAAO,KAAK,GAAG,CAAC,YAAY;QAExD,MAAM,WAAW,MAAM,MAAM,IAAI,QAAQ;QAEzC,IAAI,CAAC,SAAS,EAAE,EAAE;YACd,MAAM,YAAY,MAAM,SAAS,IAAI;YACrC,QAAQ,KAAK,CAAC,CAAC,mCAAmC,EAAE,SAAS,MAAM,EAAE,EAAE;YACvE,OAAO,EAAE;QACb;QAEA,MAAM,OAAO,MAAM,SAAS,IAAI;QAEhC,IAAI,CAAC,KAAK,KAAK,IAAI,KAAK,KAAK,CAAC,MAAM,KAAK,GAAG;YACxC,QAAQ,GAAG,CAAC;YACZ,OAAO,EAAE;QACb;QAEA,OAAO,KAAK,KAAK,CAAC,GAAG,CAAC,CAAC,OAAc,CAAC;gBAClC,OAAO,KAAK,KAAK,IAAI;gBACrB,KAAK,KAAK,IAAI,IAAI;YACtB,CAAC;IACL,EAAE,OAAO,OAAO;QACZ,QAAQ,KAAK,CAAC,kCAAkC;QAChD,OAAO,EAAE;IACb;AACJ;AAEA;;CAEC,GACD,SAAS,eAAe,GAAW;IAC/B,MAAM,cAAc;QAChB;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;KACH;IAED,OAAO,YAAY,IAAI,CAAC,CAAA,MAAO,IAAI,QAAQ,CAAC;AAChD;AAEA;;CAEC,GACD,SAAS,sBAAsB,GAAW;IACtC,IAAI;QACA,MAAM,WAAW,IAAI,IAAI,KAAK,QAAQ;QACtC,8BAA8B;QAC9B,OAAO,SACF,OAAO,CAAC,UAAU,IAClB,OAAO,CAAC,iCAAiC,IACzC,KAAK,CAAC,IAAI,CAAC,EAAE,CACb,OAAO,CAAC,MAAM,KACd,OAAO,CAAC,SAAS,CAAA,IAAK,EAAE,WAAW;IAC5C,EAAE,OAAM;QACJ,OAAO;IACX;AACJ;AAEA;;CAEC,GACD,SAAS,YAAY,MAAc;IAC/B,MAAM,QAAQ,OAAO,OAAO,CAAC,OAAO;IACpC,IAAI,MAAM,MAAM,KAAK,IAAI;QACrB,OAAO,CAAC,CAAC,EAAE,MAAM,KAAK,CAAC,GAAG,GAAG,EAAE,EAAE,MAAM,KAAK,CAAC,GAAG,GAAG,CAAC,EAAE,MAAM,KAAK,CAAC,IAAI;IAC1E;IACA,OAAO;AACX"}},
    {"offset": {"line": 847, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 853, "column": 0}, "map": {"version":3,"sources":["file://C%3A/Users/swizz/Desktop/Emailer/emailer/src/app/api/scrape-leads/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from \"next/server\";\r\nimport { scrapeLeads } from \"@/lib/scraper\";\r\n\r\ninterface ScrapedContact {\r\n    email: string;\r\n    name?: string;\r\n    company?: string;\r\n    phone?: string;\r\n    location?: string;\r\n    website?: string;\r\n    address?: string;\r\n    leadScore?: number;\r\n    verified?: boolean;\r\n}\r\n\r\nexport async function POST(request: NextRequest) {\r\n    try {\r\n        const { prompt } = await request.json();\r\n\r\n        if (!prompt) {\r\n            return NextResponse.json(\r\n                { error: \"Prompt is required\" },\r\n                { status: 400 }\r\n            );\r\n        }\r\n\r\n        console.log('[API] Lead scraping request:', prompt);\r\n\r\n        // Check if Google Search API is configured\r\n        if (!process.env.GOOGLE_SEARCH_API_KEY || !process.env.GOOGLE_SEARCH_ENGINE_ID) {\r\n            return NextResponse.json({\r\n                contacts: [],\r\n                count: 0,\r\n                source: 'error',\r\n                message: 'Google Custom Search API not configured. Please add GOOGLE_SEARCH_API_KEY and GOOGLE_SEARCH_ENGINE_ID to your environment variables.',\r\n            });\r\n        }\r\n\r\n        // REAL SCRAPING ONLY - NO AI FALLBACK\r\n        const result = await scrapeLeads(prompt, 25);\r\n\r\n        console.log(`[API] Real scraper found ${result.leads.length} leads`);\r\n\r\n        if (result.leads.length === 0) {\r\n            return NextResponse.json({\r\n                contacts: [],\r\n                count: 0,\r\n                source: 'real_scraper',\r\n                message: result.errors.length > 0\r\n                    ? `No leads found. Errors: ${result.errors.slice(0, 3).join('; ')}`\r\n                    : 'No leads found matching your search. Try a different location or business type.',\r\n                errors: result.errors,\r\n            });\r\n        }\r\n\r\n        // Only return contacts that have verified real data\r\n        const contacts: ScrapedContact[] = result.leads\r\n            .filter(lead => lead.verified !== false) // Only verified or unverified (not explicitly false)\r\n            .map(lead => ({\r\n                email: lead.email,\r\n                name: lead.name || undefined, // Don't include if empty\r\n                company: lead.company || undefined,\r\n                phone: lead.phone || undefined,\r\n                location: lead.location || undefined,\r\n                website: lead.website || undefined,\r\n                address: lead.address || undefined,\r\n                leadScore: lead.leadScore,\r\n                verified: lead.verified,\r\n            }));\r\n\r\n        return NextResponse.json({\r\n            contacts,\r\n            count: contacts.length,\r\n            source: 'real_scraper',\r\n            totalScraped: result.totalScraped,\r\n            errors: result.errors.length > 0 ? result.errors.slice(0, 5) : undefined,\r\n        });\r\n    } catch (error) {\r\n        console.error(\"Scrape leads error:\", error);\r\n        const errorMessage = error instanceof Error ? error.message : \"Unknown error\";\r\n        return NextResponse.json(\r\n            {\r\n                contacts: [],\r\n                count: 0,\r\n                source: 'error',\r\n                error: `Failed to scrape leads: ${errorMessage}`\r\n            },\r\n            { status: 500 }\r\n        );\r\n    }\r\n}\r\n"],"names":[],"mappings":";;;AAAA;AACA;;;AAcO,eAAe,KAAK,OAAoB;IAC3C,IAAI;QACA,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,QAAQ,IAAI;QAErC,IAAI,CAAC,QAAQ;YACT,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACpB;gBAAE,OAAO;YAAqB,GAC9B;gBAAE,QAAQ;YAAI;QAEtB;QAEA,QAAQ,GAAG,CAAC,gCAAgC;QAE5C,2CAA2C;QAC3C,IAAI,CAAC,QAAQ,GAAG,CAAC,qBAAqB,IAAI,CAAC,QAAQ,GAAG,CAAC,uBAAuB,EAAE;YAC5E,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;gBACrB,UAAU,EAAE;gBACZ,OAAO;gBACP,QAAQ;gBACR,SAAS;YACb;QACJ;QAEA,sCAAsC;QACtC,MAAM,SAAS,MAAM,CAAA,GAAA,gIAAA,CAAA,cAAW,AAAD,EAAE,QAAQ;QAEzC,QAAQ,GAAG,CAAC,CAAC,yBAAyB,EAAE,OAAO,KAAK,CAAC,MAAM,CAAC,MAAM,CAAC;QAEnE,IAAI,OAAO,KAAK,CAAC,MAAM,KAAK,GAAG;YAC3B,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;gBACrB,UAAU,EAAE;gBACZ,OAAO;gBACP,QAAQ;gBACR,SAAS,OAAO,MAAM,CAAC,MAAM,GAAG,IAC1B,CAAC,wBAAwB,EAAE,OAAO,MAAM,CAAC,KAAK,CAAC,GAAG,GAAG,IAAI,CAAC,OAAO,GACjE;gBACN,QAAQ,OAAO,MAAM;YACzB;QACJ;QAEA,oDAAoD;QACpD,MAAM,WAA6B,OAAO,KAAK,CAC1C,MAAM,CAAC,CAAA,OAAQ,KAAK,QAAQ,KAAK,OAAO,qDAAqD;SAC7F,GAAG,CAAC,CAAA,OAAQ,CAAC;gBACV,OAAO,KAAK,KAAK;gBACjB,MAAM,KAAK,IAAI,IAAI;gBACnB,SAAS,KAAK,OAAO,IAAI;gBACzB,OAAO,KAAK,KAAK,IAAI;gBACrB,UAAU,KAAK,QAAQ,IAAI;gBAC3B,SAAS,KAAK,OAAO,IAAI;gBACzB,SAAS,KAAK,OAAO,IAAI;gBACzB,WAAW,KAAK,SAAS;gBACzB,UAAU,KAAK,QAAQ;YAC3B,CAAC;QAEL,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;YACrB;YACA,OAAO,SAAS,MAAM;YACtB,QAAQ;YACR,cAAc,OAAO,YAAY;YACjC,QAAQ,OAAO,MAAM,CAAC,MAAM,GAAG,IAAI,OAAO,MAAM,CAAC,KAAK,CAAC,GAAG,KAAK;QACnE;IACJ,EAAE,OAAO,OAAO;QACZ,QAAQ,KAAK,CAAC,uBAAuB;QACrC,MAAM,eAAe,iBAAiB,QAAQ,MAAM,OAAO,GAAG;QAC9D,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACpB;YACI,UAAU,EAAE;YACZ,OAAO;YACP,QAAQ;YACR,OAAO,CAAC,wBAAwB,EAAE,cAAc;QACpD,GACA;YAAE,QAAQ;QAAI;IAEtB;AACJ"}},
    {"offset": {"line": 925, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}